---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

[My CV(PDF)](/files/Liuzihua_resume_en.pdf)  



Education
======
* B.S. in South China Univer sity of Technology (SCUT), 2016-2020
* M.S. in Tokyo Institute of Technology, 2020-2023
* Ph.D in Tokyo Institute of Technology, 2023-2026(expected)

Work experience(Internships)
======
* 2023/06-2023/11: 
  * Sensetime Japan
  * Duties included: As a researcher intern, we developed VSRD, a novel method for monocular 3D objectdetection with weak 2D supervision, avoiding the need for3D labels. Our approach utilizes multi-view 3D auto-labeling to generate pseudo labels for training. We introduce an Instance-aware volumetric silhouette rendering to create instance masks from a signed distance field (SDF) representation of objects. For optimizing 3D bounding boxes directly, we decompose each object's SDF into a basic cuboid SDF and a residual distance field (RDF), enabling end-to-end optimization by aligning rendered and actual instance masks. The Paper has been accepted for Conference of Computer Vision and Pattern Recognition.(CVPR2024)
  * Supervisor: Hiroki Sakuma

* 2022/02-2022/04: 
  * Megvii Shanghai Research Institue.
  * Focus on Parking Slot detection and segmentation for autonomous driving.Add a angle constrain to the corners of the parking slot which improve the recall rate of parking slot detection by 10%.Impose a novel training strategy for data augmentation which make full use of the limited training data, which greatly improve the detection at ill-position like image edges and occluded regions. It was finally accepted by Megvii as the IPM pipeline for automatic parking algorithm.
  * Supervisor: Zhao Yang
  
Skills
======
* Pytorch 
* Computer Vision


Publications 
======
*  VSRD: Volumetric Silhouette Rendering for Weakly Supervised 3D Object Detection. <br /> 
**Z.Liu\***, H.Sakuma\*, M.Okutomi  
Proceedings of the IEEE/CVF Computer Vision and Pattern Recognition. (CVPR 2024)  
\* is the equal contribution.<br />
[[project page]](http://www.ok.sc.e.titech.ac.jp/res/VSRD/)&emsp;[[paper]](https://arxiv.org/abs/2404.00149)&emsp;[[code]](https://github.com/skmhrk1209/VSRD) 

*  CFDNet: A Generalizable Foggy Stereo Matching Network with Contrastive Feature Distillation. <br />
**Z. Liu**, Y. Li, M.Okutomi  
IEEE International Conference on Robotics and Automation (ICRA2024)<br />
[[project page]](http://www.ok.sc.e.titech.ac.jp/res/FStereo/icra2024.html)&emsp;[[paper]](https://arxiv.org/abs/2402.18181)&emsp;[[code]]()  

* Global Occlusion-Aware Transformer for Robust Stereo Matching.<br /> **Z. Liu**, Y. Li, M.Okutomi  
Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision(WACV 2024) <br />[[project page]](http://www.ok.sc.e.titech.ac.jp/res/DeepSM/wacv2024.html)&emsp;[[paper]](https://openaccess.thecvf.com/content/WACV2024/html/Liu_Global_Occlusion-Aware_Transformer_for_Robust_Stereo_Matching_WACV_2024_paper.html)&emsp;[[code]](https://github.com/Magicboomliu/GOAT)  


* Digging Into Normal Incorporated Stereo Matching.  <br />
**Z. Liu**, S. Zhang, Z. Wang, M. Okutomi  
Proceedings of the 30th ACM International Conference on Multimedia(ACM MM 2022)<br />[[project page]](http://www.ok.sc.e.titech.ac.jp/res/DeepSM/acmmm22.html)&emsp;
[[paper]](https://dl.acm.org/doi/abs/10.1145/3503161.3548312)&emsp;[[code]](https://github.com/Magicboomliu/NINet)  
  


Service and leadership
======
* Guangdong Registrated Volunteer.
